\section{Retrospective}\label{S1Retro}
Following the finalization of the first sprint, we met with the other
groups in order to discuss the problems which occured
throughout the sprint, and to reflect upon the development/organizational
process used.\nl

During the sprint three problems were encountered. The first problem is that
some tasks did not have a descriptive title nor a well defined explanation.
This lead to some back and forth discussion between the SCRUM group and other
groups in order to figure out what the task meant.\\
Another problem occured as a result of several groups sharing the same task on
phabricator. When one group declared the task as resolved on phabricator, it
would be resolved for the other groups as well. As a result it was agreed that
when multiple groups work on the same tasks they should consult each other as to
when it can be classified as resolved.\\
An issue which every group encountered, but proved to be quite the problem for
group SW609 and SW610, was that Jenkins, Artifactory and Gradle did not
function.
This resulted in the project being unable to be built, and continued to be a
problem throughout the sprint, despite the best efforts of group SW614.\nl

During the sprint it was decided that each group should post a short daily
update to keep the SCRUM-team up to date on what each group was doing. This was
not a success as it resulted in what several groups felt like unnecessary
overhead. Quite a lot of work was done on refactoring, implementing the
code-style and other tasks that did not quite result in a meaningful daily
update. As a result it was decided to drop the daily updates.\nl

It was decided that every future task should contain an estimate of how many
man-hours it takes to finish it. This should be estimated when the
task is created and if proven unrealistic can be changed. This is done to
better measure productivity and workload throughout the sprint. It also helps
reducing the apparent workload that comes with having a lot of tasks. We faced a
similar problem in that we had quite a lot of tasks that ended up being resolved
quickly. This left us with a lot of time towards the end of sprint, even when we
were given a few additional tasks.

\subsection{Code Review}
It was also decided that the groups should begin to use code reviews during
sprint 2 in order to test how the added overhead affected the quality of the
product. This is despite the feedback from prior semester that suggests that
they found that the added overhead was not worth added quality. This is done
since it would be beneficial to make our own experiences and it would provide
the SCRUM Master group with some possible collaboration work.\nl

Our code review process is described in \autoref{CRP}, and in short it contains
a list of requirements and suggestions as to how the code review should proceed.
This ensures that every group has the same expectations as to how the review
should proceed. To better facilitate this, a code review template is available,
see \autoref{CRT}. This template is an easy reference to the author group, the
reviewer group and which Git repository the code is in. Both of these documents
are available to all the groups and are meant to reduce some of the additional
work caused by doing code reviews.

\subsection{Evaluation}

The sprint ended with 55.3\% of tasks being declared resolved. A lot of the
unresolved tasks have solutions but have not been tested since Jenkins,
Artifactory and Gradle currently cannot be used to build the project. The
burndown chart for this sprint was constructed in a wrong way, but can still provide
some clarity, see \autoref{S1BurndownChart}.

\figx[0.6]{S1BurndownChart}{The burndown chart for the first sprint}

The sprint is evaluated as a success despite the percentage of resolved
tasks. This is because the development and SCRUM method proved successful
at allowing the information to flow between groups.



